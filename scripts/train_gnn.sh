#!/bin/bash

# Script to train Graph Neural Networks on text classification tasks
# This script uses the graph data generated by generate_graphs.sh

# Set the Python path to include the parent directory
export PYTHONPATH=$PYTHONPATH:$(dirname $(dirname $(realpath $0)))

# Default parameters
dataset_name="stanfordnlp/sst2"
module="GCNConv"
hidden_dim=256
num_layers=3
dropout=0.5
layer_norm=false
residual=false
pooling="max"
num_relations=3
batch_size=32
num_epochs=10
learning_rate=0.0001
weight_decay=0.01
lr_scheduler="linear"
warmup_steps=0
seed=42
cuda=false
fp16=false
label_source="llm"
data_dir="/app/src/Clean_Code/output/pytorch_geometric"
output_dir="/app/src/Clean_Code/output/gnn_results"

# Help message
show_help() {
    echo "Usage: $0 [options]"
    echo ""
    echo "Options:"
    echo "  --dataset_name NAME      Dataset name (e.g., setfit/ag_news, stanfordnlp/sst2) [default: setfit/ag_news]"
    echo "  --module TYPE            GNN module type (GCNConv, GATConv, GraphConv, SAGEConv, RGCNConv, RGATConv) [default: GCNConv]"
    echo "  --hidden_dim SIZE        Hidden dimension size [default: 256]"
    echo "  --num_layers NUM         Number of GNN layers [default: 3]"
    echo "  --dropout RATE           Dropout rate [default: 0.5]"
    echo "  --layer_norm             Use layer normalization"
    echo "  --residual               Use residual connections"
    echo "  --pooling METHOD         Graph pooling method (max, mean, add) [default: max]"
    echo "  --num_relations NUM      Number of relation types for relational GNNs [default: 3]"
    echo "  --batch_size SIZE        Batch size for training [default: 32]"
    echo "  --num_epochs NUM         Number of training epochs [default: 10]"
    echo "  --learning_rate RATE     Learning rate [default: 0.0001]"
    echo "  --weight_decay RATE      Weight decay for AdamW optimizer [default: 0.01]"
    echo "  --lr_scheduler TYPE      Learning rate scheduler type (linear, cosine, constant) [default: linear]"
    echo "  --warmup_steps NUM       Number of warmup steps for the scheduler [default: 0]"
    echo "  --seed NUM               Random seed for reproducibility [default: 42]"
    echo "  --cuda                   Use CUDA for training"
    echo "  --fp16                   Use mixed precision training"
    echo "  --label_source SOURCE    Source of labels (original, llm) [default: llm]"
    echo "  --data_dir DIR           Directory containing the graph data [default: /app/src/Clean_Code/output/embeddings/graphs]"
    echo "  --output_dir DIR         Directory to save results [default: /app/src/Clean_Code/output/gnn_results]"
    echo "  --help                   Show this help message and exit"
}

# Parse command line arguments
while [[ $# -gt 0 ]]; do
    case "$1" in
        --dataset_name)
            dataset_name="$2"
            shift 2
            ;;
        --module)
            module="$2"
            shift 2
            ;;
        --hidden_dim)
            hidden_dim="$2"
            shift 2
            ;;
        --num_layers)
            num_layers="$2"
            shift 2
            ;;
        --dropout)
            dropout="$2"
            shift 2
            ;;
        --layer_norm)
            layer_norm=true
            shift
            ;;
        --residual)
            residual=true
            shift
            ;;
        --pooling)
            pooling="$2"
            shift 2
            ;;
        --num_relations)
            num_relations="$2"
            shift 2
            ;;
        --batch_size)
            batch_size="$2"
            shift 2
            ;;
        --num_epochs)
            num_epochs="$2"
            shift 2
            ;;
        --learning_rate)
            learning_rate="$2"
            shift 2
            ;;
        --weight_decay)
            weight_decay="$2"
            shift 2
            ;;
        --lr_scheduler)
            lr_scheduler="$2"
            shift 2
            ;;
        --warmup_steps)
            warmup_steps="$2"
            shift 2
            ;;
        --seed)
            seed="$2"
            shift 2
            ;;
        --cuda)
            cuda=true
            shift
            ;;
        --fp16)
            fp16=true
            shift
            ;;
        --label_source)
            label_source="$2"
            shift 2
            ;;
        --data_dir)
            data_dir="$2"
            shift 2
            ;;
        --output_dir)
            output_dir="$2"
            shift 2
            ;;
        --help)
            show_help
            exit 0
            ;;
        *)
            echo "Unknown option: $1"
            show_help
            exit 1
            ;;
    esac
done

# Validate module type
valid_modules=("GCNConv" "GATConv" "GraphConv" "SAGEConv" "RGCNConv" "RGATConv")
if [[ ! " ${valid_modules[@]} " =~ " ${module} " ]]; then
    echo "Error: Invalid module type. Must be one of: ${valid_modules[*]}"
    exit 1
fi

# Validate pooling method
valid_pooling=("max" "mean" "add")
if [[ ! " ${valid_pooling[@]} " =~ " ${pooling} " ]]; then
    echo "Error: Invalid pooling method. Must be one of: ${valid_pooling[*]}"
    exit 1
fi

# Validate label source
valid_label_sources=("original" "llm")
if [[ ! " ${valid_label_sources[@]} " =~ " ${label_source} " ]]; then
    echo "Error: Invalid label source. Must be one of: ${valid_label_sources[*]}"
    exit 1
fi

# Extract provider and dataset name for directory structure
provider=$(echo "$dataset_name" | cut -d'/' -f1)
dataset_short=$(echo "$dataset_name" | cut -d'/' -f2)

# Check if data directory exists
train_data_dir="${data_dir}/${provider}/${dataset_short}/train_${label_source}_labels"
test_data_dir="${data_dir}/${provider}/${dataset_short}/test_${label_source}_labels"

if [ ! -d "$train_data_dir" ] || [ ! -d "$test_data_dir" ]; then
    echo "Error: Data directories not found:"
    echo "  Train: $train_data_dir"
    echo "  Test: $test_data_dir"
    echo ""
    echo "Please run generate_graphs.sh first to create the graph data."
    exit 1
fi

# Create output directory if it doesn't exist
mkdir -p "$output_dir"

# Print training configuration
echo "Training GNN for dataset: $dataset_name"
echo "Module type: $module"
echo "Hidden dimension: $hidden_dim"
echo "Number of layers: $num_layers"
echo "Dropout rate: $dropout"
echo "Layer normalization: $layer_norm"
echo "Residual connections: $residual"
echo "Pooling method: $pooling"
echo "Number of relation types: $num_relations"
echo "Batch size: $batch_size"
echo "Number of epochs: $num_epochs"
echo "Learning rate: $learning_rate"
echo "Weight decay: $weight_decay"
echo "Learning rate scheduler: $lr_scheduler"
echo "Warmup steps: $warmup_steps"
echo "Random seed: $seed"
echo "Using CUDA: $cuda"
echo "Using FP16: $fp16"
echo "Label source: $label_source"
echo "Data directory: $data_dir"
echo "Output directory: $output_dir"
echo ""

# Construct command with all arguments
cmd="python -m src.Clean_Code.GNN_Training.train \
    --dataset_name $dataset_name \
    --module $module \
    --hidden_dim $hidden_dim \
    --num_layers $num_layers \
    --dropout $dropout \
    --pooling $pooling \
    --num_relations $num_relations \
    --batch_size $batch_size \
    --num_epochs $num_epochs \
    --learning_rate $learning_rate \
    --weight_decay $weight_decay \
    --lr_scheduler $lr_scheduler \
    --warmup_steps $warmup_steps \
    --seed $seed \
    --label_source $label_source \
    --data_dir $data_dir \
    --output_dir $output_dir"

# Add boolean flags if enabled
if [ "$layer_norm" = true ]; then
    cmd="$cmd --layer_norm"
fi

if [ "$residual" = true ]; then
    cmd="$cmd --residual"
fi

if [ "$cuda" = true ]; then
    cmd="$cmd --cuda"
fi

if [ "$fp16" = true ]; then
    cmd="$cmd --fp16"
fi

# Run the training command
echo "Starting training..."
echo "$cmd"
eval "$cmd"

# Check if training was successful
if [ $? -eq 0 ]; then
    echo "Training completed successfully!"
    
    # Find the results directory (most recent one)
    results_dir=$(find "$output_dir" -maxdepth 1 -type d -name "${dataset_short}*" | sort -r | head -n 1)
    
    if [ -n "$results_dir" ]; then
        echo "Results saved to: $results_dir"
        
        # Print best test F1 score
        metrics_file="$results_dir/metrics.json"
        if [ -f "$metrics_file" ]; then
            best_f1=$(python -c "import json; f=open('$metrics_file'); data=json.load(f); print(max(data.get('test_f1_scores', [0]))); f.close()")
            echo "Best test F1 score: $best_f1"
        fi
    else
        echo "Warning: Could not find results directory"
    fi
else
    echo "Error: Training failed"
    exit 1
fi

echo "Done!"
